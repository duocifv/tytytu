import random
import time
import requests
import traceback
from pydantic import BaseModel
from langchain_core.messages import HumanMessage
from langchain.output_parsers import PydanticOutputParser
from services.groq_service import chat_groq
from services.seo_service import SEOContentPipeline
import feedparser  # Ä‘á»ƒ parse RSS Google News


MAX_NEWS_LENGTH = 8000  # giá»›i háº¡n kÃ½ tá»± cho field news


# -----------------------------
# 1ï¸âƒ£ Äá»‹nh nghÄ©a schema output (4 field)
# -----------------------------
class DataAnalysisOutput(BaseModel):
    thien: str
    dia: str
    nhan: str
    key_event: str


# -----------------------------
# 2ï¸âƒ£ Thu tháº­p dá»¯ liá»‡u Ä‘a nguá»“n
# -----------------------------
def collect_data():
    results = {"heaven": {}, "earth": {}, "human": {}}

    try:
        # ThiÃªn â€“ NOAA Kp Index
        try:
            kp_url = "https://services.swpc.noaa.gov/products/noaa-planetary-k-index.json"
            kp_data = requests.get(kp_url, timeout=10).json()
            results["heaven"]["kp_index"] = kp_data[-1] if kp_data else {}
        except Exception as e:
            results["heaven"]["error"] = str(e)

        # Äá»‹a â€“ USGS Earthquakes
        try:
            quake_url = "https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_day.geojson"
            quake_data = requests.get(quake_url, timeout=10).json()
            results["earth"]["earthquakes"] = quake_data.get("features", [])[:5]
        except Exception as e:
            results["earth"]["error"] = str(e)

        # NhÃ¢n â€“ Google News RSS
        try:
            news_url = "https://news.google.com/rss?hl=vi&gl=VN&ceid=VN:vi"
            feed = feedparser.parse(news_url)
            news_items = []
            for entry in feed.entries[:50]:  # gom 50 tin má»›i nháº¥t
                news_items.append(f"{entry.title} - {entry.link}")
            news_text = "\n".join(news_items)
            # Cáº¯t giá»›i háº¡n kÃ½ tá»±
            if len(news_text) > MAX_NEWS_LENGTH:
                news_text = news_text[:MAX_NEWS_LENGTH] + "\n[...]"
            results["human"]["news"] = news_text

           # -----------------------------
            # SEO / Trends (thay tháº¿ pháº§n gá»‘c)
            # -----------------------------
            seo = SEOContentPipeline()
            seed_keywords = ["thiÃªn tai", "dá»‹ch bá»‡nh", "kinh táº¿", "thá»i sá»±"]
            seo_data = {}

            RETRY_COUNT = 3
            DELAY_BETWEEN_REQUESTS = 1.5  # giÃ¢y

            def safe_fetch(fetch_fn):
                """Thá»­ láº¡i nhiá»u láº§n náº¿u fetch lá»—i"""
                for i in range(RETRY_COUNT):
                    try:
                        return fetch_fn()
                    except Exception as e:
                        wait = 2 ** i + random.random()
                        time.sleep(wait)
                return {"status": "error", "error": "Failed after retries"}

            for kw in seed_keywords:
                seo_data[kw] = {}

                # Láº¥y related keywords
                seo_data[kw]["related_keywords"] = safe_fetch(lambda: seo.fetch_keywords(kw))
                time.sleep(DELAY_BETWEEN_REQUESTS)

                # Láº¥y competitor titles
                seo_data[kw]["competitor_titles"] = safe_fetch(lambda: seo.fetch_competitor_titles(kw))
                time.sleep(DELAY_BETWEEN_REQUESTS)

            results["human"]["seo_trends"] = seo_data

        except Exception as e:
            results["human"]["error"] = str(e)

    except Exception as e:
        results["error"] = str(e)

    return results


# -----------------------------
# 3ï¸âƒ£ Node chÃ­nh: gom + phÃ¢n tÃ­ch
# -----------------------------
def data_analysis_node(state: dict) -> dict:
    topic = state.get("topic", "Tá»•ng há»£p ThiÃªn â€“ Äá»‹a â€“ NhÃ¢n")

    # 1. Gom dá»¯ liá»‡u thÃ´
    raw_data = collect_data()
    print("ğŸ“Œ 1 - data_analysis_node - ok", raw_data)
    # 2. Chuáº©n bá»‹ parser JSON (4 trÆ°á»ng)
    parser = PydanticOutputParser(pydantic_object=DataAnalysisOutput)

    # 3. Prompt Groq
    safe_state = {k: ("..." if k == "messages" else v) for k, v in state.items()}
    prompt = (
        f"Dá»¯ liá»‡u state: {safe_state}\n\n"
        f"Chá»§ Ä‘á»: {topic}\n\n"
        f"Dá»¯ liá»‡u thu tháº­p:\n{raw_data}\n\n"
        "Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘a chiá»u.\n"
        "HÃ£y Ä‘á»c ká»¹ dá»¯ liá»‡u trÃªn vÃ  phÃ¢n tÃ­ch chi tiáº¿t theo 4 yáº¿u tá»‘:\n\n"
        "1. ThiÃªn (Heaven / ThiÃªn vÄƒn â€“ KhÃ­ quyá»ƒn â€“ VÅ© trá»¥)\n"
        "- PhÃ¢n tÃ­ch dá»¯ liá»‡u bÃ£o tá»«, hoáº¡t Ä‘á»™ng máº·t trá»i, khÃ­ quyá»ƒn, hiá»‡n tÆ°á»£ng vÅ© trá»¥.\n"
        "- Nháº­n Ä‘á»‹nh tÃ¡c Ä‘á»™ng tá»›i khÃ­ háº­u, viá»…n thÃ´ng, vá»‡ tinh, hÃ ng khÃ´ng.\n\n"
        "2. Äá»‹a (Earth / Äá»‹a cháº¥t â€“ Äá»‹a lÃ½ â€“ MÃ´i trÆ°á»ng)\n"
        "- PhÃ¢n tÃ­ch dá»¯ liá»‡u Ä‘á»‹a cháº¥n, Ä‘á»™ng Ä‘áº¥t, nÃºi lá»­a, biáº¿n Ä‘á»•i mÃ´i trÆ°á»ng, khÃ­ háº­u.\n"
        "- LÃ m rÃµ khu vá»±c chá»‹u tÃ¡c Ä‘á»™ng, má»©c Ä‘á»™ nguy hiá»ƒm vÃ  há»‡ quáº£ lÃ¢u dÃ i.\n\n"
        "3. NhÃ¢n (Human / XÃ£ há»™i â€“ Y khoa â€“ Äá»i sá»‘ng)\n"
        "- PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng tá»›i con ngÆ°á»i: sá»©c khá»e cá»™ng Ä‘á»“ng, y táº¿, xÃ£ há»™i, kinh táº¿, chÃ­nh trá»‹.\n"
        "- Náº¿u cÃ³ thiÃªn tai/dá»‹ch bá»‡nh/khá»§ng hoáº£ng, lÃ m rÃµ áº£nh hÆ°á»Ÿng tá»›i cá»™ng Ä‘á»“ng.\n\n"
        "4. Key Event (Sá»± kiá»‡n chÃ­nh ná»•i báº­t nháº¥t)\n"
        "- XÃ¡c Ä‘á»‹nh sá»± kiá»‡n quan trá»ng nháº¥t trong ngÃ y.\n"
        "- Giáº£i thÃ­ch táº¡i sao sá»± kiá»‡n nÃ y ná»•i báº­t vÃ  liÃªn há»‡ tá»›i ThiÃªn â€“ Äá»‹a â€“ NhÃ¢n.\n\n"
        "---\n\n"
        "ğŸ¯ YÃªu cáº§u xuáº¥t JSON\n"
        "Tráº£ vá» Ä‘Ãºng Ä‘á»‹nh dáº¡ng JSON vá»›i 4 trÆ°á»ng:\n\n"
        "{\n"
        '  "thien": "PhÃ¢n tÃ­ch chi tiáº¿t ThiÃªn...",\n'
        '  "dia": "PhÃ¢n tÃ­ch chi tiáº¿t Äá»‹a...",\n'
        '  "nhan": "PhÃ¢n tÃ­ch chi tiáº¿t NhÃ¢n...",\n'
        '  "key_event": "MÃ´ táº£ sá»± kiá»‡n chÃ­nh ná»•i báº­t nháº¥t."\n'
        "}\n\n"
        f"Tráº£ vá» JSON Ä‘Ãºng format:\n{parser.get_format_instructions()}"
    )

    # 4. Gá»i Groq GPT
    try:
        raw_result = chat_groq(prompt)
        result = parser.parse(raw_result)
    except Exception as e:
        traceback.print_exc()
        result = DataAnalysisOutput(
            thien="KhÃ´ng láº¥y Ä‘Æ°á»£c",
            dia="KhÃ´ng láº¥y Ä‘Æ°á»£c",
            nhan="KhÃ´ng láº¥y Ä‘Æ°á»£c",
            key_event="Error",
        )

    # print("ğŸ“Œ 1 - data_analysis_node - ok", result.model_dump())
    msg = HumanMessage(content=f"data_analysis_node completed for '{topic}'")
    return {
        "status": "done",
        "messages": [msg],
        "daily": result.model_dump(),
    }


# -----------------------------
# 5ï¸âƒ£ Example cháº¡y thá»­
# -----------------------------
if __name__ == "__main__":
    state = {"topic": "Tá»•ng há»£p ThiÃªn â€“ Äá»‹a â€“ NhÃ¢n"}
    output = data_analysis_node(state)
    print(output)
