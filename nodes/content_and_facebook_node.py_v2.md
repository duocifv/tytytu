# main_pipeline_with_two_tier.py
import os
from typing import TypedDict
import uuid
import traceback
import random
from io import BytesIO
import requests
from pydantic import BaseModel
from langchain_core.messages import HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain.output_parsers import PydanticOutputParser
from PIL import Image as PILImage
from brain.notion_logger import get_hexagram_log
from services.generate_video_service import generate_video
from services.llm_service import llm
from services.facebook_service import FacebookPipeline
from services.rag_service import RAGRetriever

# -----------------------------
# Th∆∞ m·ª•c l∆∞u t·∫°m
# -----------------------------
TEMP_DIR = "generated_images"
os.makedirs(TEMP_DIR, exist_ok=True)

# -----------------------------
# 1Ô∏è‚É£ Model JSON chu·∫©n
# -----------------------------
class ContentOutput(BaseModel):
    fb_title: str
    fb_description: str
    image_prompt: str
    daily_stoic_prompt: str
    daily_stoic: str
    quote_author: str
    poster_tone: str

def safe_parse(parser, text: str):
    try:
        return parser.parse(text)
    except Exception:
        traceback.print_exc()
        return ContentOutput(
            fb_title="Fallback Title",
            fb_description="Fallback description",
            image_prompt="city street rainy",
            daily_stoic="Fallback stoic",
            quote_author="Unknown",
            poster_tone="neutral"
        )

def extract_simple_notion(notion_raw: dict, keys=None):
    if keys is None:
        keys = ["Nhan", "Dia", "Thien", "Summary", "KeyEvent", "Health", "Work", "Effect", 
                "Trend", "Finance", "Psychology", "Family", "Spiritual", "Community"]
    simple = {}
    try:
        props = notion_raw.get("properties", {})
        for k in keys:
            v = props.get(k)
            if not v:
                continue
            rich_text = v.get("rich_text", [])
            if rich_text and isinstance(rich_text, list):
                simple[k] = " ".join(rt.get("plain_text", "") for rt in rich_text).strip()
    except Exception as e:
        print(e)
    return simple

# -----------------------------
# 2Ô∏è‚É£ T·∫°o ·∫£nh t·ª´ Hugging Face Space
# -----------------------------
def generate_image_from_prompt(prompt: str) -> PILImage.Image | None:
    url = "https://duocifv-tytytu-image.hf.space/generate-image"
    payload = {"prompt": prompt}
    headers = {"Content-Type": "application/json"}
    try:
        response = requests.post(url, json=payload, headers=headers, timeout=2000)
        response.raise_for_status()
        img = PILImage.open(BytesIO(response.content)).convert("RGB")
        print("‚úÖ Image generated successfully")
        return img
    except Exception as e:
        print("‚ùå L·ªói t·∫°o ·∫£nh:", e)
        traceback.print_exc()
        return None

# -----------------------------
# Helper: ƒëƒÉng media l√™n Facebook
# -----------------------------
def post_media(pipeline: FacebookPipeline, video_path=None, image_path=None, fb_title="", fb_description=""):
    fb_title_safe = fb_title[:100]
    try:
        if video_path:
            fb_result = pipeline.post_video(video_path=video_path, title=fb_title_safe, description=fb_description)
            success = bool(fb_result.get("id"))
        elif image_path:
            fb_result = pipeline.run(image_path=image_path, title=fb_title, description=fb_description)
            success = bool(fb_result.get("published", False))
        else:
            success = False
    except Exception:
        traceback.print_exc()
        success = False
    return success

# -----------------------------
# 3Ô∏è‚É£ Semantic Randomization helpers
# -----------------------------
def paraphrase_text(text: str, style="friendly") -> str:
    """
    S·ª≠ d·ª•ng LLM ƒë·ªÉ:
    - Vi·∫øt l·∫°i n·ªôi dung ho√†n to√†n m·ªõi (paraphrase)
    - Gi·ªØ c√πng √Ω t∆∞·ªüng
    - Chuy·ªÉn sang ti·∫øng Vi·ªát chu·∫©n, th√¢n m·∫≠t, g·∫ßn g≈©i
    - √Åp d·ª•ng style t√πy ch·ªçn (v√≠ d·ª•: friendly, witty, warm)
    """
    prompt = ChatPromptTemplate.from_messages([
        ("system", "B·∫°n l√† chuy√™n gia vi·∫øt b√†i Facebook b·∫±ng ti·∫øng Vi·ªát, th√¢n m·∫≠t, d√≠ d·ªèm, g·∫ßn g≈©i."),
        ("user", f"""
            Vi·∫øt l·∫°i n·ªôi dung sau th√†nh b√†i ƒëƒÉng ho√†n to√†n m·ªõi b·∫±ng **ti·∫øng Vi·ªát**, gi·ªØ c√πng √Ω t∆∞·ªüng nh∆∞ng c√°ch di·ªÖn ƒë·∫°t kh√°c, 
            style: {style}.

            N·ªôi dung g·ªëc (c√≥ th·ªÉ l√† ti·∫øng Anh): 
            {text}

            Ch·ªâ tr·∫£ v·ªÅ **n·ªôi dung b√†i ƒëƒÉng ti·∫øng Vi·ªát**, kh√¥ng th√™m ch√∫ th√≠ch hay gi·∫£i th√≠ch.
        """)
    ])
    
    out = llm.invoke(prompt.format())
    return getattr(out, "content", text)

def randomize_image_prompt(prompt: str) -> str:
    """LLM sinh prompt h√¨nh ·∫£nh kh√°c d·ª±a tr√™n concept"""
    prompt_wrap = ChatPromptTemplate.from_messages([
        ("system", "You are an expert AI image prompt creator. Always reply in English."),
        ("user", f"""
            Concept: {prompt}
            Please write a completely new AI image prompt, different but keeping the same idea,
            concise (‚â§77 characters), in English, suitable for the context of a Facebook post.
            Return only the prompt text, no explanation.
        """)
    ])
    out = llm.invoke(prompt_wrap.format())
    new_prompt = getattr(out, "content", prompt)
    return new_prompt[:77]

# ƒê·ªãnh nghƒ©a schema JSON
class QuoteSchema(BaseModel):
    new_quote: str
    new_author: str

def randomize_daily_quote(prompt: str) -> tuple[str, str]:
    parser = PydanticOutputParser(pydantic_object=QuoteSchema)
    parser_instructions = parser.get_format_instructions()

    daily_stoic_template = ChatPromptTemplate.from_messages([
        ("system", "B·∫°n l√† chuy√™n gia vi·∫øt c√¢u tri·∫øt l√Ω, truy·ªÅn nƒÉng l∆∞·ª£ng. T·∫≠p trung ng·∫Øn g·ªçn, x√∫c t√≠ch."),
        ("user",
         "prompt: {prompt}\n"
         "Nhi·ªám v·ª•: T·ª´ c√¢u sau, t·∫°o 1 c√¢u m·ªõi DUY NH·∫§T (paraphrase) c√≥ c√πng √Ω nghƒ©a v√† 1 t√°c gi·∫£ bi·∫øn th·ªÉ AN TO√ÄN.\n\n"
         "Y√™u c·∫ßu nghi√™m ng·∫∑t: ch·ªâ tr·∫£ v·ªÅ JSON v·ªõi c√°c tr∆∞·ªùng:\n"
         "{parser_instructions}\n"
         "- new_quote: c√¢u tri·∫øt l√Ω paraphrase, gi·ªØ √Ω nghƒ©a v√† d·ªãch sang ti·∫øng vi·ªát.\n"
         "- new_author: t√°c gi·∫£ bi·∫øn th·ªÉ an to√†n (v√≠ d·ª• 'Marcus Aurelius').\n"
         "Tr·∫£ v·ªÅ ch·ªâ JSON, kh√¥ng th√™m g√¨ kh√°c.")
    ]).partial(parser_instructions=parser_instructions)

    prompt_content = daily_stoic_template.format(prompt=prompt)
    llm_output = llm.invoke(prompt_content)

    content_obj = safe_parse(parser, getattr(llm_output, "content", str(llm_output)))

    return content_obj.new_quote, content_obj.new_author  # D√πng .new_quote thay v√¨ ["new_quote"]


# -----------------------------
# 4Ô∏è‚É£ Main pipeline
# -----------------------------
def content_and_facebook_node(state: dict):
    msg_list = []
    fb_success = False
    temp_image_path = None
    temp_video_path = None

    # 1Ô∏è‚É£ L·∫•y d·ªØ li·ªáu Notion
    notion_raw = get_hexagram_log()
    notion_data = extract_simple_notion(notion_raw)
    print("‚úÖ D·ªØ li·ªáu r√∫t g·ªçn t·ª´ Notion:", notion_data)
    if not notion_data:
        notion_data = {"Summary": "Kh√¥ng c√≥ d·ªØ li·ªáu h√¥m nay"}

    notion_data_str = str(notion_data)
    parser = PydanticOutputParser(pydantic_object=ContentOutput)

    # -----------------------------
    # 2Ô∏è‚É£ Tier 1: Ph√¢n t√≠ch d·ªØ li·ªáu
    # -----------------------------
    p_analysis = ChatPromptTemplate.from_messages([
        ("system", "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu c·ªông ƒë·ªìng."),
        ("user",
         "D·ªØ li·ªáu JSON t·ª´ Notion: {notion_data}\n"
         "H√£y ph√¢n t√≠ch v√† r√∫t ra c√°c insight ch√≠nh:\n"
         "- T√¨nh h√¨nh thi√™n tai, d·ªãch b·ªánh, kinh t·∫ø, t√¢m l√Ω\n"
         "- T√°c ƒë·ªông ƒë·∫øn s·ª©c kh·ªèe, c√¥ng vi·ªác, ƒë·ªùi s·ªëng gia ƒë√¨nh\n"
         "- G·ª£i √Ω c√°ch ·ª©ng ph√≥, chƒÉm s√≥c s·ª©c kh·ªèe v√† tinh th·∫ßn\n"
         "Tr·∫£ v·ªÅ vƒÉn b·∫£n s√∫c t√≠ch, d·ªÖ hi·ªÉu.")
    ]).partial(notion_data=notion_data_str)
    prompt_analysis = p_analysis.format(notion_data=notion_data_str)
    insight_text = getattr(llm.invoke(prompt_analysis), "content", "")
    
    # -----------------------------
    # 3Ô∏è‚É£ RAG: l·∫•y d·ªØ li·ªáu th·ª±c t·∫ø
    # -----------------------------
    rag = RAGRetriever(sources=["VNExpress","Kh√≠ t∆∞·ª£ng Th·ªßy vƒÉn","WHO"])
    rag_info = rag.retrieve(notion_data)
    if isinstance(rag_info, dict):
        rag_info = str(rag_info)

    # -----------------------------
    # 4Ô∏è‚É£ Tier 2: Vi·∫øt content d·ª±a tr√™n insight + RAG
    # -----------------------------
    parser_instructions = parser.get_format_instructions()
    p_content = ChatPromptTemplate.from_messages([
    ("system", "You are a social media editor, writing casual, friendly Facebook posts."),
    ("user", """
        Based on the analysis insights: {insight}
        And real-world data from RAG: {rag_info}

        Write a casual, friendly, and useful Facebook post, like a friend talking to the community.

        Requirements:
        - Opening: describe a concrete life scene (e.g., empty caf√©, child coughing, motorbike stalled in rain‚Ä¶)
        - Body:
        + Everyday + informative: integrate real-world data influence.
        + Practical advice: health, safety, daily life tips.
        + Community angle: mention sharing and helping each other.
        - Ending: warm, witty, gentle tone, like giving advice to loved ones.
        - Daily Stoic: include a short, uplifting philosophical sentence.
        - Length: 150‚Äì250 words.
        - Style: friendly, emotional, balancing concern and hope.
        - Optional: one hashtag at the end.
        - Do not use academic language, dry lists, or technical data.

        Output: JSON with 6 fields:
        - fb_title (50‚Äì100 characters)
        - fb_description (‚â§500 characters)
        - image_prompt: short (‚â§77 characters), accurately describing the opening image, contextually relevant.
        - daily_stoic_prompt: short, concise, uplifting philosophical sentence suitable for the post, in English.
        - poster_tone (choose from: ["happy","sad","neutral","vibrant","warm","cool","pastel","bold","calm","dark","light","luxury","natural"])

        Only output correctly formatted JSON. Do not add any extra text.

        Schema: {parser_instructions}
        """)
        ]).partial(parser_instructions=parser_instructions)


    prompt_content = p_content.format(insight=insight_text, rag_info=rag_info,parser_instructions=parser_instructions)
    llm_output = llm.invoke(prompt_content)
    content_obj = safe_parse(parser, getattr(llm_output, "content", str(llm_output)))

    # 5Ô∏è‚É£ Semantic randomization
    content_obj.fb_description = paraphrase_text(content_obj.fb_description)
    content_obj.daily_stoic, content_obj.quote_author = randomize_daily_quote(
        content_obj.daily_stoic_prompt
    )
    content_obj.image_prompt = randomize_image_prompt(content_obj.image_prompt)

    print("üìå Content JSON sau randomization:", content_obj)

    # 6Ô∏è‚É£ T·∫°o ·∫£nh + video
    if content_obj.image_prompt:
        pil_img = generate_image_from_prompt(content_obj.image_prompt)
        if pil_img:
            temp_image_path = os.path.join(TEMP_DIR, f"v_{uuid.uuid4().hex[:4]}.jpg")
            try:
                pil_img.save(temp_image_path, format="JPEG", quality=95)
            except Exception:
                traceback.print_exc()
                temp_image_path = None

            if temp_image_path:
                temp_video_path = os.path.join(TEMP_DIR, f"v_{uuid.uuid4().hex[:4]}.mp4")
                try:
                    generate_video(
                        temp_image_path,
                        content_obj.daily_stoic or content_obj.fb_description,
                        content_obj.quote_author or None,
                        output=temp_video_path,
                        size=(1080,1350),
                        total_frames=180,
                        fps=30
                    )
                    if not os.path.exists(temp_video_path):
                        temp_video_path = None
                except Exception:
                    traceback.print_exc()
                    temp_video_path = None
            msg_list.append(HumanMessage(content="‚úÖ Video created" if temp_video_path else "‚ùå Video creation failed"))
        else:
            msg_list.append(HumanMessage(content="‚ùå Image generation failed"))

    # 7Ô∏è‚É£ ƒêƒÉng FB
    if temp_video_path or temp_image_path:
        pipeline = FacebookPipeline()
        fb_success = post_media(
            pipeline,
            video_path=temp_video_path,
            image_path=temp_image_path,
            fb_title=content_obj.fb_title,
            fb_description=content_obj.fb_description
        )
        msg_list.append(HumanMessage(content=f"Facebook: {'‚úÖ Published' if fb_success else '‚ùå Failed'}"))

    # 8Ô∏è‚É£ Cleanup temp
    for path in [temp_image_path, temp_video_path]:
        try:
            if path and os.path.exists(path):
                os.remove(path)
        except Exception:
            traceback.print_exc()

    return {"status": "done", "messages": msg_list, "published": fb_success}
