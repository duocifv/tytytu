"""
C√°c t√°c v·ª• x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n s·ª≠ d·ª•ng m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLM).
"""

from prefect import task
from typing import Dict, Any, Optional
from langchain.chat_models import init_chat_model
import logging
from dotenv import load_dotenv
from tasks.tool_tasks import lay_danh_sach_cong_cu
from tasks.llm_client import llm

load_dotenv()

# Logger chu·∫©n Python
logger = logging.getLogger(__name__)
logging.basicConfig(
    format="%(asctime)s - %(levelname)s - %(message)s",
    level=logging.INFO
)

@task(name="phan-tich-y-dinh")
async def phan_tich_y_dinh(cau_hoi: str) -> str:
    """
    Ph√¢n t√≠ch √Ω ƒë·ªãnh c·ªßa c√¢u h·ªèi ng∆∞·ªùi d√πng.

    Args:
        cau_hoi: N·ªôi dung c√¢u h·ªèi c·∫ßn ph√¢n t√≠ch

    Returns:
        str: T√™n c√¥ng c·ª• ho·∫∑c h√†nh ƒë·ªông ph√π h·ª£p
    """
    logger.info(f"üîç Ph√¢n t√≠ch √Ω ƒë·ªãnh: {cau_hoi[:50]}...")
    # L·∫•y tool list ƒë·ªông
    tools = lay_danh_sach_cong_cu()
    tool_text = "\n".join([f"- {k}: {v}" for k, v in tools.items()])
    
    prompt_text = f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω th√¥ng minh. H√£y ph√¢n t√≠ch c√¢u h·ªèi v√† ch·ªçn c√¥ng c·ª• ph√π h·ª£p.

C√°c c√¥ng c·ª• c√≥ s·∫µn:
{tool_text}

C√¢u h·ªèi: {cau_hoi}

Tr·∫£ l·ªùi b·∫±ng t√™n c√¥ng c·ª• ph√π h·ª£p nh·∫•t.
"""
    try:
        response = await llm.ainvoke(prompt_text)
        return response.content.strip().lower()
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi ph√¢n t√≠ch √Ω ƒë·ªãnh: {e}")
        return "hoi_dap"  # M·∫∑c ƒë·ªãnh

@task(name="tao-phat-bieu")
async def tao_phat_bieu(
    cau_hoi: str,
    nguyen_canh: str = "",
    phan_hoi_cong_cu: str = ""
) -> str:
    """
    T·∫°o ph·∫£n h·ªìi t·ª± nhi√™n d·ª±a tr√™n c√¢u h·ªèi v√† ng·ªØ c·∫£nh.

    Args:
        cau_hoi: N·ªôi dung c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
        nguyen_canh: Th√¥ng tin b·ªï sung t·ª´ c∆° s·ªü d·ªØ li·ªáu
        phan_hoi_cong_cu: K·∫øt qu·∫£ t·ª´ c√°c c√¥ng c·ª• ƒë√£ th·ª±c thi

    Returns:
        str: Ph·∫£n h·ªìi ƒë∆∞·ª£c t·∫°o ra
    """
    logger.info("üí≠ T·∫°o ph·∫£n h·ªìi...")

    prompt_text = f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch. H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p.

C√¢u h·ªèi: {cau_hoi}

Ng·ªØ c·∫£nh b·ªï sung:
{nguyen_canh or "Kh√¥ng c√≥ th√¥ng tin b·ªï sung."}

K·∫øt qu·∫£ t·ª´ c√¥ng c·ª•:
{phan_hoi_cong_cu or "Kh√¥ng c√≥ k·∫øt qu·∫£ t·ª´ c√¥ng c·ª•."}

H√£y tr·∫£ l·ªùi m·ªôt c√°ch ng·∫Øn g·ªçn v√† ch√≠nh x√°c.
"""
    try:
        response = await llm.ainvoke(prompt_text)
        return response.content.strip()
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi t·∫°o ph·∫£n h·ªìi: {e}")
        return "Xin l·ªói, t√¥i g·∫∑p kh√≥ khƒÉn khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i sau."
