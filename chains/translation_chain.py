# chains/translation_chain.py
from typing import Dict, Any
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from services.llm_service import llm  # Gemini instance

def run_translation_chain(input_text: str) -> Dict[str, Any]:
    """
    Node 2: ThÃ´ng dá»‹ch
    - Dá»‹ch ngÃ´n ngá»¯ khÃ¡ch â†’ ká»¹ thuáº­t
    - Chuáº©n hÃ³a thuáº­t ngá»¯
    - Táº¡o brief chuáº©n
    """

    # 1ï¸âƒ£ Táº¡o prompt templates
    p1 = ChatPromptTemplate.from_template(
        "Báº¡n lÃ  trá»£ lÃ½ ká»¹ thuáº­t. Dá»‹ch ná»™i dung sau sang ngÃ´n ngá»¯ ká»¹ thuáº­t: {input_text}"
    )
    p2 = ChatPromptTemplate.from_template(
        "Dá»±a trÃªn ná»™i dung sau: {step1_translate}, hÃ£y chuáº©n hÃ³a thuáº­t ngá»¯ chuyÃªn ngÃ nh."
    )
    p3 = ChatPromptTemplate.from_template(
        "Dá»±a trÃªn ná»™i dung Ä‘Ã£ chuáº©n hÃ³a: {step2_normalize}, táº¡o má»™t brief ngáº¯n gá»n, chuáº©n."
    )

    # 2ï¸âƒ£ Táº¡o chain chuáº©n LangChain 2025 vá»›i RunnableLambda Ä‘á»ƒ feed dict
    chain3 = (
        p1 | llm
        | RunnableLambda(lambda step1_translate: {"step1_translate": step1_translate}) | p2 | llm
        | RunnableLambda(lambda step2_normalize: {"step2_normalize": step2_normalize}) | p3 | llm
    )

    # 3ï¸âƒ£ Invoke chain vá»›i input_text
    final_result = chain3.invoke({"input_text": input_text})

    # 4ï¸âƒ£ Log thÃ´ng tin
    print("   â”œâ”€ ğŸŒ Dá»‹ch ngÃ´n ngá»¯ khÃ¡ch â†’ ká»¹ thuáº­t")
    print("   â”œâ”€ ğŸ“– Chuáº©n hÃ³a thuáº­t ngá»¯")
    print("   â””â”€ ğŸ“ Táº¡o brief chuáº©n")

    return final_result
