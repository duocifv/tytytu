# chains/coordination_chain.py
from typing import Dict, Any
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda
from services.llm_service import llm  # Gemini instance

def run_coordination_chain(input_text: str) -> Dict[str, Any]:
    """
    Node 3: Trung tÃ¢m (PM + CSKH)
    - Láº­p káº¿ hoáº¡ch, timeline
    - PhÃ¢n cÃ´ng cÃ´ng viá»‡c
    - BÃ¡o cÃ¡o & giá»¯ liÃªn láº¡c KH

    Tráº£ vá» dict: {"result_chain1", "result_chain2", "final_result"}
    """

    # 1ï¸âƒ£ Táº¡o prompt templates
    p1 = ChatPromptTemplate.from_template(
        "Báº¡n lÃ  PM. Dá»±a trÃªn input: {input_text}\n\n"
        "HÃ£y láº­p káº¿ hoáº¡ch chi tiáº¿t vÃ  timeline (liá»‡t kÃª cÃ¡c má»‘c chÃ­nh, duration tá»«ng má»‘c)."
    )
    p2 = ChatPromptTemplate.from_template(
        "Dá»±a trÃªn káº¿ hoáº¡ch sau: {result_chain1}\n\n"
        "HÃ£y phÃ¢n cÃ´ng cÃ´ng viá»‡c cho tá»«ng vai trÃ²/nhÃ¢n sá»± (má»—i nhiá»‡m vá»¥ ngáº¯n gá»n, ai chá»‹u trÃ¡ch nhiá»‡m)."
    )
    p3 = ChatPromptTemplate.from_template(
        "Dá»±a trÃªn phÃ¢n cÃ´ng cÃ´ng viá»‡c: {result_chain2}\n\n"
        "Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p (summary) Ä‘á»ƒ gá»­i khÃ¡ch hÃ ng vÃ  hÆ°á»›ng dáº«n giá»¯ liÃªn láº¡c (1-2 cÃ¢u hÃ nh Ä‘á»™ng)."
    )

    # 2ï¸âƒ£ Táº¡o chain chuáº©n LangChain 2025 vá»›i RunnableLambda Ä‘á»ƒ feed dict
    chain3 = (
        p1 | llm
        | RunnableLambda(lambda result_chain1: {"result_chain1": result_chain1}) | p2 | llm
        | RunnableLambda(lambda result_chain2: {"result_chain2": result_chain2}) | p3 | llm
    )

    # 3ï¸âƒ£ Invoke chain vá»›i input_text
    final_result = chain3.invoke({"input_text": input_text})

    # 4ï¸âƒ£ Log thÃ´ng tin
    print("   â”œâ”€ ğŸ“… Láº­p káº¿ hoáº¡ch, timeline")
    print("   â”œâ”€ ğŸ‘¥ PhÃ¢n cÃ´ng cÃ´ng viá»‡c")
    print("   â””â”€ ğŸ“¢ BÃ¡o cÃ¡o & giá»¯ liÃªn láº¡c KH")

    return final_result
